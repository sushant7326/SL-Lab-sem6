# -*- coding: utf-8 -*-
"""24-01-30-2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UajQD3NaNgs6zhTeRxBUTUu48fuI_tpS
"""

# Import Library
import pandas as pd # Data Manipulation
import numpy as np # Data Manipulation
import matplotlib.pyplot as plt # Data Visualisation
import seaborn as sns # Data Visualisation
import warnings

# To ignore all the warnings
warnings.filterwarnings("ignore")

df = pd.read_csv("insurance.csv")

print("\nNumber of rows and columns in the data set : ", df.shape)
df.head() # Top 5 rows

df.info()

sns.lmplot(x="bmi", y="charges", data=df, aspect=2, height=5)
plt.xlabel("BMI as indipendent variable")
plt.ylabel("Insurance charges as dependent/response variable")
plt.title("Charge vs BMI")

# Exploratory Data Ananlysis
df.describe()

# Check for missing values
missing_values = df.isnull()

# Summarize the missing values
missing_values_count = missing_values.sum()

# Display the result
print("Missing values in each column")
print(missing_values_count)

# Correlation Plot
corr = df.corr()
sns.heatmap(corr,cmap="coolwarm", annot=True)

f = plt.figure(figsize=(12,4))
ax = f.add_subplot(121)
sns.distplot(df['charges'], bins=50, color='r', ax=ax)
ax.set_title("Distribution of insurance charges")

ax = f.add_subplot(122)
sns.distplot(np.log10(df['charges']), bins=40, color='b', ax=ax)
ax.set_title('Distribution of insurance charges in $log$ scale')
ax.set_xscale('log')

f = plt.figure(figsize=(13,6))
ax = f.add_subplot(121)
sns.violinplot(x='sex', y='charges', data=df, palette='Wistia', ax=ax)
ax.set_title('Violin plot of Charges vs Sex')

ax = f.add_subplot(122)
sns.violinplot(x='smoker', y='charges', data=df, palette='magma', ax=ax)
ax.set_title('Violin plot of Charges vs Smoker')

plt.figure(figsize=(13,6))
sns.boxplot(x='children', y='charges', hue='sex', data=df, palette='rainbow')
plt.title('Boxplot of Charges vs Children')

f = plt.figure(figsize=(13,6))
ax = f.add_subplot(121)
sns.scatterplot(x='age', y='charges', data=df, palette='magma', hue='smoker', ax=ax)
ax.set_title('Scatter plot of Charges vs Age')

ax = f.add_subplot(122)
sns.scatterplot(x='bmi', y='charges', data=df, palette='viridis', hue='smoker')
ax.set_title('Scatter plot of Charges vs Age')

"""# Data Processing Encoding
Machine Learning Algirithms cannot work with categorical data directly. Categorical data must be converted to number


```
Label Encoding
One-hot Encoding
Dummy variable trap
```


"""

# Dummy Variable
categorical_columns = ['sex', 'smoker', 'region']
df_encode = pd.get_dummies(data=df, prefix='OHE', prefix_sep='_', columns=categorical_columns, drop_first=True, dtype='int8')

df_encode.head()

df.shape

df_encode.info()

# Log Transform
df_encode['charges'] = np.log(df_encode['charges'])

"""**Train Test Split**"""

from sklearn.model_selection import train_test_split
X = df_encode.drop('charges', axis=1) # Independent Variable
Y = df_encode['charges'] # Dependent Variable

X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.3, random_state=23)

"""**Model Building**"""

# Scikit Learning Module
from sklearn.linear_model import LinearRegression
lin_reg = LinearRegression()
lin_reg.fit(X_train, Y_train)

"""**Getting the coefficients and intercept**"""

coefficients = lin_reg.coef_
intercept = lin_reg.intercept_

# Display the coefficients and intercept
coefficients_df = pd.DataFrame({'Feature': X_train.columns, 'Coefficient':coefficients})
print("Intercept : ", intercept)
print("Coefficients : ")
print(coefficients_df)

# Sklearn Regression Module
Y_pred_sk = lin_reg.predict(X_test)

# Evaluation MSE
from sklearn.metrics import mean_squared_error
J_mse_sk = mean_squared_error(Y_pred_sk, Y_test)

# R-Square
R_square_sk = lin_reg.score(X_test, Y_test)
print("MSE = ", J_mse_sk)
print("R-Square = ", R_square_sk)

# Number of Observations
n = len(Y_test)

# Number of features
p = X_test.shape[1]

# Calculating adjusted R-Square
adjusted_r_squared = 1 - (1-R_square_sk)*(n-1)/(n-p-1)
print("Adjusted R-Squared value is : ", adjusted_r_squared)

"""**Model Validation**"""

# Check for Linearity
f = plt.figure(figsize=(13,5))

# Scatter Plot
ax = f.add_subplot(121)
ax.scatter(Y_test, Y_pred_sk, color='r')
ax.set_title("Check for Linearity:\n Actual vs Predicted Value")
ax.set_xlabel("Actual Values")
ax.set_ylabel("Predicted Values")

# Check for Residual Normality and Mean
ax = f.add_subplot(122)
sns.distplot((Y_test-Y_pred_sk), ax=ax, color='b')
ax.axvline((Y_test-Y_pred_sk).mean(), color='k', linestyle='--')
ax.set_title("Check for Residual Normalityu and Mean:\n Residual Error")
ax.set_xlabel("Residuals")

plt.tight_layout()
plt.show()

# Check for Multivariate Normality
# Q-Q Plot
f,ax = plt.subplots(1,2,figsize=(13,6))
import scipy as sp
_,(_,_,r) = sp.stats.probplot((Y_test-Y_pred_sk), fit=True, plot=ax[0])
ax[0].set_title("Check for Multivariate Normality: \nQ-Q Plot")

# Check for Homoscedasticity
sns.scatterplot(y = (Y_test-Y_pred_sk), x = Y_pred_sk, ax=ax[1], color='r')
ax[1].set_title("Check for Homoscedasticity: \nResidual vs Predicted")

# Check for Multicollinearity
# Variance Inflation Factor

VIF = 1/(1-R_square_sk)
VIF

"""**Logistic Regression**"""

df = pd.read_csv("User_Data.csv")
df.head()

df.set_index("User ID")

df.info()

df.describe()

X = df.iloc[:, 2:3].values
Y = df.iloc[:, 4].values

# Splitting into Training and Test Data
from sklearn.model_selection import train_test_split
X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.3, random_state=23)

# Feature Scaling
from sklearn.preprocessing import StandardScaler
sc_X = StandardScaler()
X_train = sc_X.fit_transform(X_train)
X_test = sc_X.transform(X_test)

# Fitting the Logistic Regression into the Training Set
from sklearn.linear_model import LogisticRegression

classifier = LogisticRegression(random_state=0)
classifier.fit(X_train, Y_train)

# Predicting the test set results
Y_pred = classifier.predict(X_test)

from sklearn.metrics import classification_report
# Generate the classification result
report = classification_report(Y_test, Y_pred)

# Display the report
print("Classification Report: \n", report)

from sklearn.metrics import accuracy_score
accuracy = accuracy_score(Y_test, Y_pred)
accuracy

# Making the confusion matrix

from sklearn.metrics import confusion_matrix
cm = confusion_matrix(Y_test, Y_pred)
cm

# DataFrame from Confusion Matrix
cm_df = pd.DataFrame(cm, index = ['Actual 0', 'Actual 1'], columns = ['Predicted 0', 'Predicted 1'])
sns.heatmap(cm_df, annot=True, fmt='d', cmap="Blues")

