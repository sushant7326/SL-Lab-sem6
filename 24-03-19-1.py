# -*- coding: utf-8 -*-
"""24-03-19-1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17hSlecEpW3pqWAKNHg7zwie-dX2YXlQa
"""

import numpy as np
import pandas as pd

import matplotlib.pyplot as plt
from sklearn import preprocessing
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
import seaborn as sns
from keras.layers import Dense, BatchNormalization, Dropout
from keras.models import Sequential
from keras import callbacks
from sklearn.metrics import confusion_matrix, classification_report

data = pd.read_csv("User_Data.csv")

data.info()

df = data.set_index("User ID")

df

X = df.iloc[:, 2:3].values
Y = df.iloc[:, 3].values

# Splitting the dataset into Training and Test Set
from sklearn.model_selection import train_test_split
X_Train, X_Test, Y_Train, Y_Test = train_test_split(X,Y, test_size = 0.25, random_state=0)

# Feature Scaling
from sklearn.preprocessing import StandardScaler
sc_X = StandardScaler()
X_Train = sc_X.fit_transform(X_Train)
X_Test = sc_X.transform(X_Test)

early_stopping = callbacks.EarlyStopping(
    min_delta = 0.001,    # minimum amount of change to count as improvement
    patience = 50,        # how many epochs to wait before stopping
    restore_best_weights=True
)

# Initialising the CNN
model = Sequential()

# Layers
model.add(Dense(units=16, kernel_initializer='uniform', activation='relu', input_dim=1))
model.add(Dense(units=8, kernel_initializer='uniform', activation='relu'))
model.add(Dropout(0.25))
model.add(Dense(units=4, kernel_initializer='uniform', activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(units=1, kernel_initializer='uniform', activation='sigmoid'))


# Compiling the ANN
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])


# Train the ANN
history = model.fit(X_Train, Y_Train, batch_size=32, epochs=500, callbacks=[early_stopping], validation_split=0.2)

import pandas as pd
history_df = pd.DataFrame(history.history)
history_df.loc[:, ['loss', 'val_loss']].plot(title='Cross-entropy')
history_df.loc[:, ['accuracy', 'val_accuracy']].plot(title='Accuracy')

# Predicting the test set results
y_pred = model.predict(X_Test)
y_pred = np.where(y_pred > 0.5,1,0)

# Generate Confusion Matrix
cf_matrix = confusion_matrix(Y_Test, y_pred)

# Plot Confusion Matrix
plt.figure(figsize = (12,8))
sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True, cmap='Blues', fmt='g', cbar=False, annot_kws={'size':15})
plt.xlabel('Predicted Label')
plt.ylabel('True Labels')
plt.show()

print(classification_report(Y_Test, y_pred))
